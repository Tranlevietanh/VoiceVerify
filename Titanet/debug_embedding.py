#!/usr/bin/env python3
"""
Script debug ƒë·ªÉ ki·ªÉm tra t·∫°i sao cosine similarity th·∫•p
"""
import torch
import torchaudio
import torch.nn.functional as F
import numpy as np
from nemo.collections.asr.models import EncDecSpeakerLabelModel

# ===== LOAD TITANET-L =====
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üîß S·ª≠ d·ª•ng device: {device}")

model = EncDecSpeakerLabelModel.restore_from("titanet-l.nemo", map_location=device)
model = model.to(device)
model.eval()
print("‚úÖ ƒê√£ load TitaNet-L model")

# ===== H√ÄM L·∫§Y EMBEDDING C√ì DEBUG =====
@torch.no_grad()
def get_embedding_debug(wav, sr, label=""):
    print(f"  üîç [{label}] Input shape: {wav.shape}, SR: {sr}")
    
    # ƒê·∫£m b·∫£o mono
    if wav.shape[0] > 1:
        wav = wav[:1, :]
        print(f"  üìª [{label}] Converted to mono: {wav.shape}")
    
    # Resample v·ªÅ 16kHz
    if sr != 16000:
        wav = torchaudio.functional.resample(wav, sr, 16000)
        sr = 16000
        print(f"  üîÑ [{label}] Resampled to 16kHz: {wav.shape}")

    # Th·ªëng k√™ audio
    print(f"  üìä [{label}] Audio stats - Min: {wav.min():.6f}, Max: {wav.max():.6f}, Mean: {wav.mean():.6f}")
    
    # Chu·∫©n h√≥a amplitude
    max_val = wav.abs().max()
    if max_val > 0:
        wav = wav / (max_val + 1e-7)
        print(f"  üéöÔ∏è [{label}] Normalized by max value: {max_val:.6f}")
    
    # Chu·∫©n input: [B, T]
    audio_signal = wav.squeeze(0).unsqueeze(0).to(device)   # [1, T]
    audio_length = torch.tensor([audio_signal.shape[-1]], device=device)
    print(f"  üéØ [{label}] Model input: {audio_signal.shape}, length: {audio_length.item()}")

    emb, _ = model.forward(
        input_signal=audio_signal,
        input_signal_length=audio_length
    )
    
    print(f"  üß† [{label}] Raw embedding shape: {emb.shape}")
    print(f"  üìè [{label}] Raw embedding norm: {emb.norm(dim=1).item():.6f}")
    
    # L2 normalize embedding
    emb = F.normalize(emb, p=2, dim=1)
    emb_np = emb.squeeze().cpu().numpy()
    
    print(f"  ‚úÖ [{label}] Final embedding shape: {emb_np.shape}, norm: {np.linalg.norm(emb_np):.6f}")
    return emb_np

# ===== TEST: C√ôNG FILE, KH√ÅC ƒêO·∫†N =====
def test_same_file_different_segments():
    print("\n" + "="*60)
    print("üß™ TEST 1: C√πng file, kh√°c ƒëo·∫°n th·ªùi gian")
    print("="*60)
    
    file = "Vi·ªát Anh_24.9.wav"
    wav, sr = torchaudio.load(file)
    duration = wav.shape[1] / sr
    print(f"üìÅ File: {file} | Duration: {duration:.2f}s")
    
    # L·∫•y 3 ƒëo·∫°n kh√°c nhau t·ª´ c√πng file
    segment1 = wav[:, int(2*sr):int(7*sr)]    # 2-7s
    segment2 = wav[:, int(8*sr):int(13*sr)]   # 8-13s  
    segment3 = wav[:, int(15*sr):int(20*sr)]  # 15-20s
    
    emb1 = get_embedding_debug(segment1, sr, "ƒêo·∫°n 2-7s")
    emb2 = get_embedding_debug(segment2, sr, "ƒêo·∫°n 8-13s")
    emb3 = get_embedding_debug(segment3, sr, "ƒêo·∫°n 15-20s")
    
    # So s√°nh
    cos12 = F.cosine_similarity(torch.tensor(emb1).unsqueeze(0), torch.tensor(emb2).unsqueeze(0)).item()
    cos13 = F.cosine_similarity(torch.tensor(emb1).unsqueeze(0), torch.tensor(emb3).unsqueeze(0)).item()
    cos23 = F.cosine_similarity(torch.tensor(emb2).unsqueeze(0), torch.tensor(emb3).unsqueeze(0)).item()
    
    print(f"\nüìä K·∫æT QU·∫¢ SO S√ÅNH (c√πng ng∆∞·ªùi):")
    print(f"   ‚Ä¢ ƒêo·∫°n 1 vs ƒêo·∫°n 2: {cos12:.4f}")
    print(f"   ‚Ä¢ ƒêo·∫°n 1 vs ƒêo·∫°n 3: {cos13:.4f}")
    print(f"   ‚Ä¢ ƒêo·∫°n 2 vs ƒêo·∫°n 3: {cos23:.4f}")
    print(f"   ‚Ä¢ Trung b√¨nh: {(cos12+cos13+cos23)/3:.4f}")
    
    return emb1  # Tr·∫£ v·ªÅ embedding ƒë·∫ßu ti√™n l√†m reference

# ===== TEST: KH√ÅC FILE, C√ôNG NG∆Ø·ªúI =====
def test_different_files_same_person(ref_emb):
    print("\n" + "="*60)
    print("üß™ TEST 2: So s√°nh v·ªõi embedding t·ª´ test1")
    print("="*60)
    
    # Load embedding ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥
    if os.path.exists("enroll_emb.npy"):
        saved_emb = np.load("enroll_emb.npy")
        cos_saved = F.cosine_similarity(torch.tensor(ref_emb).unsqueeze(0), torch.tensor(saved_emb).unsqueeze(0)).item()
        print(f"üìÅ So s√°nh v·ªõi enroll_emb.npy: {cos_saved:.4f}")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y enroll_emb.npy")

# ===== TEST: KH√ÅC NG∆Ø·ªúI =====
def test_different_person(ref_emb):
    print("\n" + "="*60)
    print("üß™ TEST 3: So s√°nh v·ªõi ng∆∞·ªùi kh√°c")
    print("="*60)
    
    other_files = ["speaker1.wav", "speaker2.wav", "my_voice.wav", "my_voice2.wav"]
    
    for file in other_files:
        if os.path.exists(file):
            try:
                wav, sr = torchaudio.load(file)
                # L·∫•y 5s ƒë·∫ßu
                segment = wav[:, :int(5*sr)]
                emb = get_embedding_debug(segment, sr, f"File {file}")
                
                cos_sim = F.cosine_similarity(torch.tensor(ref_emb).unsqueeze(0), torch.tensor(emb).unsqueeze(0)).item()
                print(f"üìä {file}: {cos_sim:.4f}")
            except Exception as e:
                print(f"‚ùå L·ªói khi x·ª≠ l√Ω {file}: {e}")
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y {file}")

# ===== MAIN =====
if __name__ == "__main__":
    import os
    
    print("üöÄ B·∫Øt ƒë·∫ßu debug embedding...")
    
    ref_emb = test_same_file_different_segments()
    test_different_files_same_person(ref_emb)
    test_different_person(ref_emb)
    
    print("\nüéØ KHUY·∫æN NGH·ªä:")
    print("   ‚Ä¢ Cosine > 0.7: R·∫•t c√≥ th·ªÉ c√πng ng∆∞·ªùi")
    print("   ‚Ä¢ Cosine 0.4-0.7: C√≥ th·ªÉ c√πng ng∆∞·ªùi")  
    print("   ‚Ä¢ Cosine < 0.4: C√≥ th·ªÉ kh√°c ng∆∞·ªùi")
    print("   ‚Ä¢ N·∫øu c√πng ng∆∞·ªùi m√† cosine < 0.3: C√≥ v·∫•n ƒë·ªÅ v·ªÅ ch·∫•t l∆∞·ª£ng audio ho·∫∑c model")