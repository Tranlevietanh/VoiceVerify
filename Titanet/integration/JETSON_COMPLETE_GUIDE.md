# üöÄ H∆∞·ªõng D·∫´n Tri·ªÉn Khai Speaker Verification tr√™n Jetson - T·ªïng H·ª£p

## üìã T·ªïng Quan

H·ªá th·ªëng Speaker Verification v·ªõi TitaNet-L ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho c√°c thi·∫øt b·ªã NVIDIA Jetson, bao g·ªìm:
- **jetson_setup.sh**: Script t·ª± ƒë·ªông c√†i ƒë·∫∑t to√†n b·ªô h·ªá th·ªëng
- **jetson_config.py**: C·∫•u h√¨nh t·ªëi ∆∞u cho t·ª´ng lo·∫°i Jetson
- **jetson_speaker_pipeline.py**: Pipeline ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a
- **jetson_monitor.py**: Gi√°m s√°t hi·ªáu su·∫•t v√† t·ªëi ∆∞u h√≥a

## üéØ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng Nhanh

### B∆∞·ªõc 1: C√†i ƒê·∫∑t T·ª± ƒê·ªông
```bash
# T·∫£i v·ªÅ v√† ch·∫°y script c√†i ƒë·∫∑t
chmod +x jetson_setup.sh
./jetson_setup.sh

# Ho·∫∑c v·ªõi t√πy ch·ªçn b·ªè qua c·∫≠p nh·∫≠t h·ªá th·ªëng
./jetson_setup.sh --skip-update
```

### B∆∞·ªõc 2: K√≠ch Ho·∫°t M√¥i Tr∆∞·ªùng
```bash
# K√≠ch ho·∫°t Python virtual environment
source venv/bin/activate

# Ki·ªÉm tra c√†i ƒë·∫∑t
python jetson_config.py
```

### B∆∞·ªõc 3: Sao Ch√©p Model
```bash
# T·∫°o th∆∞ m·ª•c models
mkdir -p ~/models

# Sao ch√©p TitaNet-L model
cp titanet-l.nemo ~/models/
```

### B∆∞·ªõc 4: Ch·∫°y Pipeline
```python
# Ch·∫°y pipeline t·ªëi ∆∞u h√≥a
python jetson_speaker_pipeline.py

# Ho·∫∑c s·ª≠ d·ª•ng trong code:
from jetson_speaker_pipeline import create_jetson_pipeline

# T·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i Jetson
pipeline = create_jetson_pipeline()

# Ho·∫∑c ch·ªâ ƒë·ªãnh c·ª• th·ªÉ
pipeline = create_jetson_pipeline(jetson_model="jetson_orin_nx")
```

## üîß C·∫•u H√¨nh Theo T·ª´ng Lo·∫°i Jetson

### Jetson Nano (RAM h·∫°n ch·∫ø)
```python
from jetson_config import create_jetson_config

config = create_jetson_config("jetson_nano")
# - S·ª≠ d·ª•ng CPU (device="cpu") 
# - Batch size = 1
# - Max audio = 15 gi√¢y
# - FP32 precision
```

### Jetson Xavier NX (C√¢n b·∫±ng)
```python
config = create_jetson_config("jetson_xavier_nx")
# - S·ª≠ d·ª•ng CUDA (device="cuda")
# - Batch size = 1 
# - Max audio = 30 gi√¢y
# - FP16 precision
```

### Jetson Orin NX (Hi·ªáu su·∫•t cao)
```python
config = create_jetson_config("jetson_orin_nx")
# - S·ª≠ d·ª•ng CUDA (device="cuda")
# - Batch size = 2
# - Max audio = 45 gi√¢y  
# - FP16 precision + TensorRT
```

### Jetson AGX Orin (T·ªëi ƒëa)
```python
config = create_jetson_config("jetson_agx_orin")
# - S·ª≠ d·ª•ng CUDA (device="cuda")
# - Batch size = 4
# - Max audio = 60 gi√¢y
# - FP16 precision + TensorRT
```

## üìä Gi√°m S√°t v√† T·ªëi ∆Øu H√≥a

### Kh·ªüi Ch·∫°y Monitor
```python
from jetson_monitor import JetsonMonitor

# T·∫°o monitor
monitor = JetsonMonitor()

# Hi·ªÉn th·ªã th√¥ng tin h·ªá th·ªëng
info = monitor.get_jetson_info()
print(f"Model: {info['model']}")
print(f"JetPack: {info['jetpack_version']}")

# B·∫Øt ƒë·∫ßu gi√°m s√°t
monitor.start_monitoring(interval=2.0)

# D·ª´ng gi√°m s√°t
monitor.stop_monitoring()

# T·∫°o b√°o c√°o hi·ªáu su·∫•t
report = monitor.generate_performance_report()
```

### Monitor trong Pipeline
```python
from jetson_speaker_pipeline import create_jetson_pipeline

pipeline = create_jetson_pipeline()

# Ki·ªÉm tra stats
stats = pipeline.get_jetson_stats()
print(f"CPU: {stats['cpu_percent']:.1f}%")
print(f"Memory: {stats['memory_percent']:.1f}%")  
print(f"Temperature: {stats['temperature_c']:.1f}¬∞C")

# X√≥a cache khi c·∫ßn thi·∫øt
pipeline.clear_cache()
```

## ‚ö° T·ªëi ∆Øu H√≥a Hi·ªáu Su·∫•t

### 1. C√†i ƒê·∫∑t Performance Mode
```bash
# Ch·∫ø ƒë·ªô hi·ªáu su·∫•t t·ªëi ƒëa
sudo nvpmodel -m 0
sudo jetson_clocks

# Ki·ªÉm tra ch·∫ø ƒë·ªô hi·ªán t·∫°i
sudo nvpmodel -q
```

### 2. T·ªëi ∆Øu Memory
```bash
# TƒÉng swap space
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# L√†m swap vƒ©nh vi·ªÖn
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

### 3. T·ªëi ∆Øu CUDA
```python
import torch

# T·ªëi ∆∞u CUDA trong code
torch.backends.cudnn.benchmark = True
torch.cuda.empty_cache()

# Mixed precision training
from torch.cuda.amp import autocast
with autocast():
    embedding = model.get_embedding(audio_path)
```

## üîÑ S·ª≠ D·ª•ng Th·ª±c T·∫ø

### V√≠ D·ª• Enrollment (ƒêƒÉng K√Ω)
```python
from jetson_speaker_pipeline import create_jetson_pipeline

# T·∫°o pipeline
pipeline = create_jetson_pipeline()

# ƒêƒÉng k√Ω speaker
audio_files = [
    "/path/to/speaker1_sample1.wav",
    "/path/to/speaker1_sample2.wav", 
    "/path/to/speaker1_sample3.wav"
]

success = pipeline.enroll_speaker("speaker_001", audio_files)
if success:
    print("‚úì Speaker enrolled successfully")
```

### V√≠ D·ª• Verification (X√°c Th·ª±c)
```python
# X√°c th·ª±c speaker
result = pipeline.verify_speaker(
    "/path/to/test_audio.wav", 
    claimed_speaker_id="speaker_001"
)

if result["success"]:
    verified = result["verified"]
    similarity = result["speakers"]["speaker_001"]["max_similarity"]
    print(f"Verified: {verified}, Similarity: {similarity:.3f}")
```

### V√≠ D·ª• Batch Processing
```python
# X·ª≠ l√Ω nhi·ªÅu file c√πng l√∫c
audio_files = [
    "/path/to/test1.wav",
    "/path/to/test2.wav", 
    "/path/to/test3.wav"
]

results = pipeline.batch_verify(audio_files)

for i, result in enumerate(results):
    if result["success"]:
        best_match = result.get("best_match", {})
        speaker = best_match.get("speaker_id", "Unknown")
        similarity = best_match.get("similarity", 0)
        print(f"File {i+1}: {speaker} ({similarity:.3f})")
```

## üê≥ Tri·ªÉn Khai Docker (T√πy Ch·ªçn)

### Build Docker Image
```bash
# T·∫°o Dockerfile cho Jetson
cat > Dockerfile.jetson << EOF
FROM nvcr.io/nvidia/l4t-pytorch:r35.2.1-pth2.0-py3

# Install dependencies
RUN apt-get update && apt-get install -y \\
    libsndfile1-dev sox ffmpeg portaudio19-dev

# Install Python packages  
RUN pip3 install librosa scipy numpy soundfile nemo-toolkit[asr]

# Copy application
WORKDIR /app
COPY . .

ENV PYTHONPATH="/app"
EXPOSE 8000

CMD ["python3", "jetson_speaker_pipeline.py"]
EOF

# Build image
sudo docker build -f Dockerfile.jetson -t speaker-verification-jetson .
```

### Ch·∫°y Container
```bash
# Ch·∫°y v·ªõi GPU support
sudo docker run --runtime nvidia --gpus all \\
    -v ~/models:/app/models \\
    -v /tmp:/tmp \\
    -p 8000:8000 \\
    speaker-verification-jetson
```

## üö® X·ª≠ L√Ω S·ª± C·ªë

### L·ªói Th∆∞·ªùng G·∫∑p

#### 1. Out of Memory
```bash
# Gi·∫£i ph√°p: TƒÉng swap space
sudo swapoff /swapfile
sudo fallocate -l 16G /swapfile  
sudo mkswap /swapfile
sudo swapon /swapfile

# Ho·∫∑c gi·∫£m batch size trong config
config.batch_size = 1
config.max_audio_duration = 15.0
```

#### 2. CUDA kh√¥ng kh·∫£ d·ª•ng
```bash
# Ki·ªÉm tra CUDA
nvcc --version
python -c "import torch; print(torch.cuda.is_available())"

# C√†i l·∫°i PyTorch cho Jetson
pip uninstall torch torchvision torchaudio
# Ch·∫°y l·∫°i jetson_setup.sh
```

#### 3. Model loading qu√° ch·∫≠m
```python
# TƒÉng timeout
import signal

def timeout_handler(signum, frame):
    raise TimeoutError("Model loading timeout")

signal.signal(signal.SIGALRM, timeout_handler)
signal.alarm(300)  # 5 ph√∫t timeout
```

#### 4. Nhi·ªát ƒë·ªô cao
```python
# Gi√°m s√°t nhi·ªát ƒë·ªô
from jetson_monitor import JetsonMonitor

monitor = JetsonMonitor()
stats = monitor.get_current_metrics()

if stats.temperature_c > 80:
    print("‚ö†Ô∏è High temperature! Consider cooling")
    # Gi·∫£m t·∫ßn s·ªë x·ª≠ l√Ω ho·∫∑c batch size
```

## üìà Benchmark Hi·ªáu Su·∫•t

### Jetson Orin NX (D·ª± ki·∫øn)
- **Model Loading**: 15-30 gi√¢y
- **Embedding Extraction**: 0.5-2.0 gi√¢y/10s audio
- **Speaker Verification**: 0.1-0.3 gi√¢y
- **RAM Usage**: 2-4GB
- **Power**: 15-25W

### Jetson Xavier NX (D·ª± ki·∫øn)
- **Model Loading**: 20-40 gi√¢y
- **Embedding Extraction**: 1.0-3.0 gi√¢y/10s audio
- **Speaker Verification**: 0.2-0.5 gi√¢y
- **RAM Usage**: 3-5GB
- **Power**: 20-30W

## üîß T√πy Ch·ªânh N√¢ng Cao

### T·∫°o Config T√πy Ch·ªânh
```python
from jetson_config import JetsonConfig

# T·∫°o config t√πy ch·ªânh
class MyJetsonConfig(JetsonConfig):
    # T√πy ch·ªânh cho use case c·ª• th·ªÉ
    similarity_threshold: float = 0.7  # Ng∆∞·ª°ng nghi√™m ng·∫∑t h∆°n
    use_vad: bool = True
    vad_threshold: float = 0.6
    max_audio_duration: float = 20.0  # Gi·ªõi h·∫°n audio ng·∫Øn h∆°n

config = MyJetsonConfig()
```

### Cache Optimization
```python
# T·ªëi ∆∞u cache cho frequent speakers
pipeline.jetson_config.cache_embeddings = True
pipeline.jetson_config.max_cache_size = 200

# X√≥a cache khi c·∫ßn
pipeline.clear_cache()
```

## üéõÔ∏è API Service (T√πy Ch·ªçn)

### T·∫°o REST API
```python
# jetson_speaker_api.py
from flask import Flask, request, jsonify
from jetson_speaker_pipeline import create_jetson_pipeline

app = Flask(__name__)
pipeline = create_jetson_pipeline()

@app.route('/enroll', methods=['POST'])
def enroll():
    data = request.json
    speaker_id = data['speaker_id']
    audio_paths = data['audio_paths']
    
    success = pipeline.enroll_speaker(speaker_id, audio_paths)
    return jsonify({'success': success})

@app.route('/verify', methods=['POST'])
def verify():
    data = request.json
    audio_path = data['audio_path']
    speaker_id = data.get('speaker_id')
    
    result = pipeline.verify_speaker(audio_path, speaker_id)
    return jsonify(result)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000)
```

### Auto-start Service
```bash
# Enable systemd service (ƒë√£ ƒë∆∞·ª£c t·∫°o b·ªüi setup script)
sudo systemctl enable speaker-verification
sudo systemctl start speaker-verification

# Ki·ªÉm tra status
sudo systemctl status speaker-verification
```

## üìù Checklist Tri·ªÉn Khai

- [ ] ‚úÖ Ch·∫°y `jetson_setup.sh` th√†nh c√¥ng
- [ ] ‚úÖ Ki·ªÉm tra PyTorch + CUDA ho·∫°t ƒë·ªông
- [ ] ‚úÖ Sao ch√©p TitaNet-L model v√†o `/home/user/models/`
- [ ] ‚úÖ Test pipeline v·ªõi `python jetson_speaker_pipeline.py`
- [ ] ‚úÖ C·∫•u h√¨nh performance mode (`nvpmodel -m 0`)
- [ ] ‚úÖ Thi·∫øt l·∫≠p swap space ƒë·ªß l·ªõn (8GB+)
- [ ] ‚úÖ Test monitor v·ªõi `python jetson_monitor.py`
- [ ] ‚úÖ Ki·ªÉm tra nhi·ªát ƒë·ªô v√† hi·ªáu su·∫•t
- [ ] ‚úÖ C·∫•u h√¨nh auto-start n·∫øu c·∫ßn
- [ ] ‚úÖ Test API endpoints n·∫øu s·ª≠ d·ª•ng

## üÜò H·ªó Tr·ª£ v√† Debug

### Ch·∫°y Diagnostic
```python
# Ki·ªÉm tra t·ªïng th·ªÉ h·ªá th·ªëng
from jetson_monitor import JetsonMonitor

monitor = JetsonMonitor()

# System info
print("=== System Information ===")
info = monitor.get_jetson_info()
for key, value in info.items():
    print(f"{key}: {value}")

# Performance check
print("\\n=== Performance Check ===")
metrics = monitor.get_current_metrics("diagnostic")
print(f"CPU: {metrics.cpu_percent:.1f}%")
print(f"Memory: {metrics.memory_percent:.1f}%")
print(f"Temperature: {metrics.temperature_c}¬∞C")

# Recommendations
print("\\n=== Recommendations ===")
recommendations = monitor.get_optimization_recommendations()
for rec in recommendations:
    print(f"‚Ä¢ {rec}")
```

### Log Files
```bash
# Xem logs c·ªßa systemd service
sudo journalctl -u speaker-verification -f

# Xem performance logs
tail -f /tmp/jetson_performance.json
```

## üéâ K·∫øt Lu·∫≠n

V·ªõi h∆∞·ªõng d·∫´n n√†y, b·∫°n c√≥ th·ªÉ:

1. **C√†i ƒë·∫∑t t·ª± ƒë·ªông**: S·ª≠ d·ª•ng `jetson_setup.sh` ƒë·ªÉ c√†i ƒë·∫∑t to√†n b·ªô h·ªá th·ªëng
2. **T·ªëi ∆∞u hi·ªáu su·∫•t**: S·ª≠ d·ª•ng c√°c config ƒë∆∞·ª£c t·ªëi ∆∞u cho t·ª´ng lo·∫°i Jetson
3. **Gi√°m s√°t h·ªá th·ªëng**: Theo d√µi nhi·ªát ƒë·ªô, RAM, CPU usage
4. **Tri·ªÉn khai production**: API service v√† auto-start capability
5. **Debug v√† troubleshoot**: Tools ƒë·ªÉ ch·∫©n ƒëo√°n v√† gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ

H·ªá th·ªëng ƒë√£ s·∫µn s√†ng cho production deployment tr√™n c√°c thi·∫øt b·ªã Jetson! üöÄ